##  1.Hashset如何检查重复

当把对象插入Hashset时，Hashset会先计算对象的hashcode值来判断对象加入的位置，同时也会与Hashset中其他对象的hashcode值作比较，如果没有相符的hashcode，HashSet会假设对象没有重复出现。但是如果发现有相同hashcode值的对象，这时会调用equals（）方法来检查hashcode相等的对象是否真的相同。如果两者相同，HashSet就不会让加入操作成功。

hashcode( )与equals( )的相关规定

1. 如果两个对象相等，则hashcode一定也是相同的
2. 两个对象相等,对两个equals方法返回true
3. 两个对象有相同的hashcode值，它们也不一定是相等的
4. 综上，equals方法被覆盖过，则hashCode方法也必须被覆盖
5. hashCode()的默认行为是对堆上的对象产生独特值。如果没有重写hashCode()，则该class的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）。

==与equals的区别

1. ==是判断两个对象或实例是不是指向同一个内存空间，equals是判断两个对象或实例所指的内存空间的值是不是相等
2. ==是对内存地址进行比较，equals是对字符串的内容进行比较
3. ==指引用是否相同，equals指值是否相同

## 2.Hashset与Hashmap的区别
Hashset实现了Set接口，是一个存储对象的集合，它底层使用Hashmap实现的，Hashset不允许元素重复，调用add( )方法添加元素，不允许元素为null,它的效率比Hashmap高。Hashset不是线程安全的。

Hashmap实现了Map接口，它是一个存储KEY-VALUE键值对的数组，允许KEY或VALUE为null,但只允许一个KEY为null，它调用put("KEY",VALUE)的方法添加元素，会把KEY为null的Entry在Hashmap数组的第一个位置。Hashmap也不是线程安全的，需要保证线程安全时建议使用conCurrentHashMap,而不是Hashtable!(Hashtable虽能保证线程安全，但效率比conCurrentHashMap低太多，基本已经没人使用了)

## 3.HashMap与Hashtable的区别

1. 初始容量和每次扩容大小不同：HashMap默认初始容量是16，扩容因子是0.75，每次扩容时新数组长度是原数组的2倍；Hashtable默认初始容量是11，之后每次扩容都变为原来的2n+1
2. 对NULL的支持：HashMap允许KEY和VALUE为NULL（只允许一个KEY为NULL）；Hashtable不允许KEY为NULL，只要put进的key值为null，就会抛出NullPointerExecption。
3. 线程安全问题：HashMap是非线程安全的，Hashtable所有的方法都经过`synchronized`关键字修饰，所以Hashtable是线程安全的。
4. 效率：由于线程安全的问题，HashMap比Hashtable效率要高一些。Hashtable已经很少使用了，如需保证线程安全可以使用conCurrentHashMap。
5. 数据结构：在Java8中，当HashMap中链表的长度大于阈值（默认为8）时时，链表会转化为红黑树，这样可以减少搜索时间。

## 4.conCurrentHashMap和Hashtable的异同
1. 相同点：二者都能保证线程安全，存储形式都是KEY-VALUE的键值对。
2. **底层数据结构不同：**conCurrentHashMap与HashMap一样，在JDK1.8之后，底层都采用了**数组+链表/红黑树**的形式，Hashtable则没有这种改变，延续了 **数组+链表**这种实现。
3. 实现线程安全的方式不同：Hashtable用`synchronized`实现线程安全，整个数组用的是同一把锁，同一时间内只能有一个线程访问同步方法，其他线程如果也想访问就会进入阻塞或轮询状态，所以Hashtable效率非常低。对于conCurrentHashMap，在JDK1.7的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。） 到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用` synchronized `和 CAS 来操作。

## 5.什么是Hash冲突?如何解决？
哈希冲突指的是在对某个元素进行哈希运算，得到一个存储地址，当要插入元素时，发现这个地址已经被其他元素占用了，这就是哈希冲突。

HashMap采用数组+链表的形式对元素进行存储，数组的每个元素又是一条链表的头结点，当新元素插入时，采用头插法插入链表，并把原结点后移，这样便解决了哈希冲突。

## 6.HashMap的简介
HashMap存储的是KEY-VALUE的键值对，每个键值对又叫做Entry，这些Entry分散存储在一个数组里，这个数组就是HashMap的主干。

HashMap最常用的方法是put和get方法。当用put方法添加元素时，会先调用一个哈希函数来计算要添加元素的位置，index=Hash("key")，这个index就是要添加的元素在HashMap中的位置。当元素增多时，就可能出现哈希冲突，HashMap采用了链表来解决哈希冲突。

HashMap数组的每个元素又是一条链表的头结点，当新元素插入时，采用头插法插入链表，并把原结点后移，这样便解决了哈希冲突。

HashMap的get方法，根据要查找的KEY做一次哈希映射，index=Hash("KEY"),找到要查找的元素在HashMap数组中的位置，如果第一个元素不是要查找的Entry,则沿着链表头节点向后查找，直到最后一个节点。

## 7.HashMap的初始长度是多少？Java8中HashMap做了怎样的优化？高并发情况下，为什么HashMap可能出现死锁？

HashMap的默认初始长度是16，默认扩容因子是0.75f。也可以人为设置初始长度，比如设置为20，则系统会创建一个长度为32的数组作为HashMap的主干。

在Java8中，当HashMap中链表的长度大于8时，会自动转化成**红黑树**进行存储，以提高检索效率。

设置合适的初始长度可以减少HashMap扩容次数，这样就可以提升性能，还可以降低因扩容导致发生BUG的几率。

当HashMap数组的长度大于初始长度与扩容因子的乘积时，HashMap会进行扩容。扩容分为两步：第一步是创建一个长度为原数组的2倍的新数组，第二部是把原数组中的数据rehash到新数组中（若某Entry在原数组中index=5，则此Entry在新数组中的位置只能是5或5+N，N指原数组的长度）。

多线程的情况下，若同时有多个线程对HashMap执行put操作，而put完之后HashMap达到了扩容临界值，此时这几个线程都会对此HashMap执行扩容操作。这就导致HashMap数组中的链表可能出现环形（有兴趣的小伙伴可以去看看源码），此时并不会发生什么问题，而当我们用HashMap来get一个不存在的KEY时，而通过此KEY算出来的index又刚好是刚才产生环形链表的位置时，程序就会进入**死锁**状态。

## 8.ArrayList和LinkedList的异同
ArrayList和Linkedist都是List接口的实现类，List集合的元素有序，可重复，可以通过索引访问指定位置的元素，有序指的是会保存元素的插入顺序。

- 二者都是线程不安全的
- ArrayList基于数组实现，可以动态扩容，随机访问效率高，查找、更新元素效率高
- LinkedList基于双向循环链表实现，插入、删除新元素时效率高，随机访问元素的效率低。
